---
title: "Chapter 6 Notes"
prefer-html: true
format: 
  docx: 
    toc: true
    highlight-style: arrow
    fig-format: retina
    fig-dpi: 300
    fig-height: 6
    fig-width: 6
editor: visual
execute:
  echo: fenced
  error: true
  output: true
editor_options: 
  chunk_output_type: inline
---

# Chapter 6: Mapping Census data with R

```{r setup}
library(tidycensus)
library(tidyverse)
library(tmap)
library(mapview)
library(leaflet)
library(mapboxapi)
library(ggiraph)
library(scales)
library(mapdeck)
library(patchwork)
library(shiny)
library(htmlwidgets)
library(sf)
library(tigris)
```

-   This chapter shows how to map Census data by using linked `geometry` parameters.

    -   We review static mapping in **ggplot2** and **tmap**

    -   We then review interactive mapping in **mapview** and **Leaflet**

## 6.1 Using geometry in tidycensus

-   `get_acs()`, `get_decennial()`, and `get_estimates()` have a `geometry` parameter

    -   when set to `TRUE`, **tigris** is called by the functions to download associated spatial data alongside the census data

```{r dc_med_inc}
options(tigris_use_cache = TRUE)

dc_income <- get_acs(
  geography = "tract",
  variables = "B19013_001",
  state = "DC",
  year = 2020,
  geometry = TRUE
)

dc_income
```

### Basic mapping of sf objects with `plot()`

-   we can visualize the estimates with plot using a bracketed column name call

```{r}
plot(dc_income["estimate"])
```

-   this returns a simple map of income variation

## 6.2 Map-making with ggplot2 and geom_sf

-   **ggplot2**'s use of `geom_sf()` allows for the development of custom spatial data visuals

### Choropleth mapping

-   Choropleth maps are very common in visualizing statistics over enumeration units

-   Below we will use **tidycensus** and **tigris** to prepare a full national map

```{r}
us_median_age <- get_acs(
  geography = "state",
  variables = "B01002_001",
  year = 2019,
  survey = "acs1",
  geometry = TRUE,
  resolution = "20m"
) %>% 
  shift_geometry()

plot(us_median_age$geometry)
```

-   we can then stylize the plot in **ggplot2**

```{r}
ggplot(data = us_median_age, aes(fill = estimate)) +
  geom_sf()
```

### Customizing ggplot2 maps

-   we have a few other tools that allow for more creative and meaningful plot construction

    -   `scale_fill_distiller()` allows us to pull down palettes from ColorBrewer

    -   `labs()` can add titles, caption(s), and a better legend label

    -   `theme_void()` removes background and gridlines from the plot area

```{r}
ggplot(data = us_median_age, aes(fill = estimate)) +
  geom_sf() +
  scale_fill_distiller(palette = "RdPu",
                       direction = 1) +
  labs(title = "Median Age by State, 2019",
       caption = "Data source: 2019 1-year ACS, US Census Bureau",
       fill = "ACS estimate") +
  theme_void()
```

## 6.3 Map-making with tmap

-   **tmap** is more specifically developed for thematic mapping than **ggplot2**

-   We will use `get_decennial()` to map race data by Census tract in Hennepin County, Minnesota

```{r}
hennepin_race <- get_decennial(
  geography = "tract",
  state = "MN",
  county = "Hennepin",
  variables = c(
    Hispanic = "P2_002N",
    White = "P2_005N",
    Black = "P2_006N",
    Native = "P2_007N",
    Asian = "P2_008N"
  ),
  summary_var = "P2_001N",
  year = 2020,
  geometry = TRUE
) %>% 
  mutate(percent = 100 * (value / summary_value))

hennepin_race
```

-   note that the data is returned in long form/"tidy" form

### Choropleth maps with tmap

-   like **ggplot2**, **tmap** uses a layer syntax appended with `+` signs

```{r}
hennepin_black <- filter(hennepin_race,
                         variable == "Black")

tm_shape(hennepin_black) +
  tm_polygons()
```

-   the default view is not classified; to graduate the fill colors we can do so using `tm_fill()`

```{r}
tm_shape(hennepin_black) +
  tm_polygons(col = "percent")
```

-   **tmap** doesn't create a continuous gradient, but rather breaks items into classes by a designated classification scheme

    -   the default classification scheme is `"pretty"` which - (per `?pretty`) - breaks the range of values into equally spaced classes demarcated by "equally spaced 'round' values"

    -   this classification scheme is sensitive to the data's underlying distribution

```{r}
hist(hennepin_black$percent)
```

-   We can use an alternative classification scheme like `"quantile"` which breaks the data down such that each class contains a (near) equal number of observations

```{r}
tm_shape(hennepin_black) +
  tm_polygons(col = "percent",
              style = "quantile",
              n = 5,
              palette = "Purples",
              title = "2020 US Census") +
  tm_layout(title = "Percent Black\nby Census tract",
            frame = FALSE,
            legend.outside = TRUE)
```

-   We may also use the commonly-selected Jenks algorithm which looks for meaningful breaks.

    -   we can use `legend.hist = TRUE` to follow classification method changes across plots

```{r}
tm_shape(hennepin_black) +
  tm_polygons(col = "percent",
              style = "jenks",
              n = 5,
              palette = "Purples",
              title = "2020 US Census",
              legend.hist = TRUE) +
  tm_layout(title = "Percent Black\nby Census tract",
            frame = FALSE,
            legend.outside = TRUE,
            bg.color = "grey70",
            legend.hist.width = 5,
            fontfamily = "Verdana")
```

### Adding reference elements to a map

-   We often include several reference elements with a map, including:

    -   basemap

    -   north arrow

    -   scale bar

-   A quick way of getting a **tmap**-compatible basemap is **rosm**

-   We may also use pre-designed or custom-designed base maps from Mapbox using **mapboxapi**

```{r}
# Non-functional code because I don't want to give Mapbox my payment info
# mb_access_token("NA")

# hennepin_tiles <- get_static_tiles(
#   location = hennepin_black,
#   zoom = 10,
#   style_id = "light-v9",
#   username = "mapbox"
# )
```

-   when defining a basemap for choropleth maps, use muted monochrome designs to avoid drowning out choropleth colors

-   basemaps are layered in tmap using `tm_rgb()`, which plots a given raster

    -   to see a basemap, add transparency to choropleth using the `alpha` argument

    -   `tm_scale_bar()` adds a scale bar

    -   `tm_compass()` adds a north arrow

    -   `tm_credits()` lets one credit data sources and basemap sources

```{r}
## Note that the basemap is commented out due to lack of a Mapbox account
# tm_shape(hennepin_tiles) +
#   tm_rgb() +
tm_shape(hennepin_black) +
  tm_polygons(col = "percent",
              style = "jenks",
              n = 5,
              palette = "Purples",
              title = "2020 US Census",
              alpha = 0.7) +
  tm_layout(title = "Percent Black\nby Census tract",
            legend.outside = TRUE,
            fontfamily = "Verdana") +
  tm_scale_bar(position = c("left", "bottom")) +
  tm_compass(position = c("right", "top")) #+
  # tm_credits("(c) Mapbox, OSM",
  #           bg.color = "white",
  #           position = c("RIGHT", "BOTTOM"))
```

-   `position` arguments allow for useful positioning

    -   using all caps will bring elements closer to flush with the map frame

### Choosing a color palette

-   Consider your data

    -   quantitative data and statistical mapping means choosing palettes that show variation effectively

    -   usually, this will be sequential palettes

        -   Sometimes, we will go from light to dark \<-\> low to high, but other palettes show lighter colors more intensely, in which case we may choose the alternative.

    -   Diverging palettes are useful for showing extremities along some axis with polarity

        -   I.E. where there is some normal median value and extremes at both ends

        -   In the context of Census mapping, diverging palettes are useful for Change over Time, with the center representing no change, and one color divergence representing a decrease over time while the other divergence represents increase over time.

    -   Categorical/Qualitative data is best mapped with Qualitative palettes where colors are unique for each class, and do not imply an ordering of classes

    -   Tools for palette selection include:

        -   [ColorBrewer](https://colorbrewer2.org/)

        -   the **viridis** library

        -   `tmaptools::palette_explorer()` includes selections from both of the above

### Alternative map types with tmap

-   Choropleth maps are best for "rates, percentages, or statistical values that are normalized for the population of areal units."

    -   not good for raw counts

    -   can make comparison difficult

-   Graduated symbols use shape symbols that scale in size relative to the data

    -   bubble map below shows bubbles where size represents count

```{r bubble-hennepin}
tm_shape(hennepin_black) +
  tm_polygons() +
  tm_bubbles(size = "value", alpha = 0.5,
             col = "navy",
             title.size = "Non-Hispanic Black - 2020 US Census") +
  tm_layout(legend.outside = TRUE,
            legend.outside.position = "bottom")
```

-   Faceted maps are grids of univariate maps where each map shows a different variable, allowing comparison between variables without trying to force them all onto a single visualization.

-   **tmap** allows for the creation of faceted maps using `tm_facets()`

-   weaknesses of faceted maps include:

    -   shared legend and classification - suppresses within-group variation

    -   difficult to discern diversity of areas

```{r hennepin-facet}
tm_shape(hennepin_race) +
  tm_facets(by = "variable", scale.factor = 4) +
  tm_fill(col = "percent",
          style = "quantile",
          n = 6,
          palette = "Blues",
          title = "Percent (2020 US Census)",) +
  tm_layout(bg.color = "grey",
            legend.position = c(-0.7, 0.15),
            panel.label.bg.color = "white")
```

-   Dot-density maps randomly place dots in polygons

    -   the quantity of dots is proportional to the size of the attribute(s) plotted

    -   different colored dots can represent different categories of a variable

-   **tidycensus** has `as_dot_density()` to prepare Census data for dot-density mapping

    -   it takes a `value` column as an argument for the attribute to be mapped

    -   `values per_dot` argument determines the proportion each dot represents of the whole

    -   `group` argument determines how to partition dots, if subgroups exist within the data

```{r hennepin-dots}
hennepin_dots <- hennepin_race %>% 
  as_dot_density(
    value = "value",
    values_per_dot = 100,
    group = "variable"
  )
```

-   the map is created with **tmap** `tm_dots()` function

    -   `tm_polygons()` provides the background

```{r hennepin-dot-density-map}
background_tracts <- hennepin_race

tm_shape(background_tracts) +
  tm_polygons(col = "white",
              border.col = "grey") +
  tm_shape(hennepin_dots) +
  tm_dots(col = "variable",
          palette = "Set1",
          size = 0.005,
          title = "1 dot = 100 people") +
  tm_layout(legend.outside = TRUE,
            title = "Race/ethnicity, \n2020 US Census")
```

-   dot-density maps risk overplotting (obscuring data by dots being too close and becoming indiscernible

-   dots in census tracts may be placed where people do not/cannot live, as water features, etc. are not taken into accounts

-   dots follow boundaries rather than the whole map when randomly plotting; this can create the visual impression in sudden breaks in density

-   one solution is *dasymetric dot-density mapping* - removing areas from polygons where people can't live before plotting the dots.

    -   **tidycensus** `as_dot_density()` function includes an `erase_water` function to remove water areas

## 6.4 Cartographic workflows with non-Census data

-   we may have data that is at a Census geography scale, but is not ACS or Census data proper

-   with this data we cannot pull geometry down using **tidycensus** `geometry = TRUE` argument

-   we may instead get shapes with **tigris** and join the data we have to Census geographies for visualization

### National election mapping with tigris shapes

-   Election data is not provided by the Census bureau

-   we will map data from the Cook Political Report for 2020 US Presidential election results

-   first we acquire and import the data

```{r political-map}
vote2020 <- read_csv("data/us_vote_2020.csv")

names(vote2020)
```

-   then we get the State-level geography we want with **tigris**

```{r states-pull}
us_states <- states(cb = TRUE, resolution = "20m") %>% 
  filter(NAME != "Puerto Rico") %>% 
  shift_geometry()
```

-   finally, we use **dplyr** `left_join()` to join the data table to the State geographies

```{r states-join}
us_states_joined <- us_states %>% 
  left_join(vote2020, by = c("NAME" = "state"))

# Quality check: did all NAME match with a state
# we expect a false to be returned for each State and DC if the "state" name matches the "NAME" name
table(is.na(us_states_joined$state))

```

-   we used a `left_join()` and started with `us_states` because we are joining the data TO the states.

-   now we plot

```{r election-map}
ggplot(us_states_joined, aes(fill = called)) +
  geom_sf(color = "white", lwd = 0.2) +
  scale_fill_manual(values = c("blue", "red")) +
  theme_void() +
  labs(fill = "Party",
       title = " 2020 US presidential election results by state",
       caption = "Note: Nebraska and Main split electoral college votes by congressional district")
```

### Understanding and working with ZCTAs

-   many agencies only release data as granular as ZIP codes

    -   ZIP codes represent *collections* of USPS routes, PO boxes, or individual buildings - they aren't areal units

-   US Census Bureau creates ZIP Code Tabulation Areas to approximate ZIP Code mapping

    -   A ZCTAs is a shape built up by Census blocks based on their most common ZIP Code

-   The IRS "Statistics of Income" data isn't available at geographies more detailed than the ZIP Code

```{r irs-data}
irs_data <- read_csv("https://www.irs.gov/pub/irs-soi/18zpallnoagi.csv")

ncol(irs_data)
```

-   The data has 153 columns; one is ZIPCODE

-   To map self-employment income, we can keep `N09400` - the number of tax returns with self-employment tax, and `N1` - which represents the total number of returns

```{r self-employment}
self_employment <- irs_data %>% 
  select(ZIPCODE, self_emp = N09400, total = N1)
```

-   we can now subset and map data in Boston, MA

```{r}
boston_zctas <- zctas(
  cb = TRUE,
  starts_with = c("021", "022", "024"),
  year = 2018
)

mapview(boston_zctas)
```

-   We can join the data-sets on `"ZCTA5CE10"` and `"ZIPCODE"`

```{r}
boston_se_data <- boston_zctas %>% 
  left_join(self_employment, by = c("GEOID10" = "ZIPCODE")) %>% 
  mutate(pct_self_emp = 100 * (self_emp / total)) %>% 
  select(GEOID10, self_emp, pct_self_emp)
```

-   We can finally build some plots of the data; first, we'll make a choropleth map

```{r}
tm_shape(boston_se_data, projection = 26918) +
  tm_fill(col = "pct_self_emp",
          palette = "Purples",
          title = "% self-employed,\n2018 IRS SOI data") +
  tm_layout(legend.position = c("LEFT", "BOTTOM"))
```

-   the choropleth map shows higher rates of self-employment in suburbs

-   If we want to see total numbers of filings, we would use `self_emp` column and visualize it as a bubble map

```{r}
tm_shape(boston_se_data) +
  tm_polygons() +
  tm_bubbles(size = "self_emp",
             alpha = 0.5,
             col = "navy",
             title.size = "Self-employed filers,\n2018 IRS SOI data")
```

## 6.5 Interactive mapping

-   The book discusses several approaches to producing interactive, non-static maps

### Interactive mapping with Leaflet

-   A popular webmap framework is the Leaflet Javascript Library

    -   in r, we can use the **leaflet package**

-   We will get data on percent of 25+ yo with bachelor's degree or higher

    -   we will look at the 2020 5Y ACS data

    -   We will pull by Census Tract

    -   We will pull for Dallas County, Texas

```{r dallas-BAs}
dallas_bachelors <- get_acs(
  geography = "tract",
  variables = "DP02_0068P",
  year = 2020,
  state = "TX",
  county = "Dallas",
  geometry = TRUE
)
```

-   Mapview gives us the ability to use `zcol` to define a variable for choropleth mapping

```{r}
mapview(dallas_bachelors, zcol = "estimate")
```

-   **tmap** also has a view mode that acts as an interactive Leaflet plot

```{r}
tmap_mode("view")

tm_shape(dallas_bachelors) +
  tm_fill(col = "estimate", palette = "magma",
          alpha = 0.5)

tmap_mode("plot")
```

-   the **leaflet** package gives more fine-grained control

    -   to reproduce the above examples with **leaflet**, run the following code chunks

```{r}
# define the color palette for 'magma'
pal <- colorNumeric(
  palette = "magma",
  domain = dallas_bachelors$estimate
)

pal(c(10, 20, 30, 40, 50))

leaflet() %>% # initialize map
  addProviderTiles(providers$Stamen.TonerLite) %>% # add basemap
  addPolygons(data = dallas_bachelors, # add census tracts
              color = ~pal(estimate),
              weight = 0.5,
              smoothFactor = 0.2,
              fillOpacity = 0.5,
              label = ~estimate) %>%
  addLegend( # add legend
    position = "bottomright",
    pal = pal,
    values = dallas_bachelors$estimate,
    title = "% with bachelor's<br/>degree"
  )
```

### Alternative approaches to interactive mapping

-   **leaflet** uses tile maps projected to Web Mercator

    -   this distorts area near poles

-   note the distortion of Alaska and near-invisibility of Alaska below

```{r}
us_value <- get_acs(
  geography = "state",
  variables = "B25077_001",
  year = 2019,
  survey = "acs1",
  geometry = TRUE,
  resolution = "20m"
)

us_pal <- colorNumeric(
  palette = "plasma",
  domain = us_value$estimate
)

leaflet() %>%
  addProviderTiles(providers$Stamen.TonerLite) %>%
  addPolygons(data = us_value,
              color = ~us_pal(estimate),
              weight = 0.5,
              smoothFactor = 0.2,
              fillOpacity = 0.5,
              label = ~estimate) %>%
  addLegend(
    position = "bottomright",
    pal = us_pal,
    values = us_value$estimate,
    title = "Median home value"
  )
```

-   If we want to make an interactive map for the whole of the US States, we can use packages such as **ggiraph**

    -   This adds interactivity to a ggplot of the maps, rather than projecting onto a Leaflet webmap

```{r}
us_value_shifted <- us_value %>%
  shift_geometry(position = "outside") %>%
  mutate(tooltip = paste(NAME, estimate, sep = ": "))

gg <- ggplot(us_value_shifted, aes(fill = estimate)) + 
  geom_sf_interactive(aes(tooltip = tooltip, data_id = NAME), 
                      size = 0.1) + 
  scale_fill_viridis_c(option = "plasma", labels = label_dollar()) + 
  labs(title = "Median housing value by State, 2019",
       caption = "Data source: 2019 1-year ACS, US Census Bureau",
       fill = "ACS estimate") + 
  theme_void() 
  
girafe(ggobj = gg) %>%
  girafe_options(opts_hover(css = "fill:cyan;"), 
                 opts_zoom(max = 10))
```

## 6.6 Advanced examples

### Mapping migration flows

-   **tidycensus** can call the ACS Migration Flows API

    -   we can map migration flows by setting `geometry = TRUE` in the `get_flows()` function

    -   this returns two point columns linking locations in the flow

-   Below we pull data for Travis County, Texas, a site of significant in-migration of late

```{r}
travis_inflow <- get_flows(
  geography = "county",
  state = "TX",
  county = "Travis",
  geometry = TRUE
) %>% 
  filter(variable == "MOVEDIN") %>% 
  na.omit() %>% 
  arrange(desc(estimate))
```

-   Now we can map the migration flows, IF we use **mapdeck** and are willing to set up API calls from MapBox, which requires providing credit card payment information

### Linking maps and charts

-   It is often useful to link visuals in an interactive manner

-   below we link a map produced with **ggplot2** to a plot of error bars for the related margins of error

    -   note that as one hovers over a polygon in the map, its affiliated error bar is highlighted

```{r}
vt_income <- get_acs(
  geography = "county",
  variables = "B19013_001",
  state = "VT",
  year = 2020,
  geometry = TRUE
) %>% 
  mutate(NAME = str_remove(NAME, " County, Vermont"))

vt_map <- ggplot(vt_income, aes(fill = estimate)) +
  geom_sf_interactive(aes(data_id = GEOID)) +
  scale_fill_distiller(palette = "Greens",
                       direction = 1,
                       guide = "none") +
  theme_void()

vt_plot <- ggplot(vt_income, aes(x = estimate, y = reorder(NAME, estimate),
                                 fill = estimate)) +
  geom_errorbar(aes(xmin = estimate - moe, xmax = estimate + moe)) +
  geom_point_interactive(color = "black", size = 4, shape = 21,
                         aes(data_id = GEOID)) +
  scale_fill_distiller(palette = "Greens", direction = 1,
                       labels = label_dollar()) +
  scale_x_continuous(labels = label_dollar()) +
  labs(title = "Household income by county in Vermont",
       subtitle = "2016-2020 American Community Survey",
       y = "",
       x = "ACS estimate (bars represent margin of error)",
       fill = "ACS estimate") +
  theme_minimal(base_size = 14)

girafe(ggobj = vt_map + vt_plot, width_svg = 10, height_svg = 5) %>% 
  girafe_options(opts_hover(css = "fill:cyan;"))
```

### Reactive mapping with Shiny

## 6.7 Working with software outside of R for cartographic projects

### Exporting maps from R

### Interoperability with other visualization software

## 6.8 Exercises
